{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe7cea-b614-43a7-a8cc-24b09ed69882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from openslide import OpenSlide\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import (\n",
    "    ConcatDataset,\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    Subset,\n",
    "    SubsetRandomSampler,\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    ")\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81404e-e4aa-498e-93e1-f7257c7066fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train_outcomes.csv') # biopsy_id, label\n",
    "test_df = pd.read_csv('./test_outcomes.csv')\n",
    "train_mapping = pd.read_csv('./train_mapping.csv') # slide_id, biopsy_id, img path\n",
    "test_mapping = pd.read_csv('./test_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671f369-3216-484b-9bae-10ba8b790a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outcome_map = {}\n",
    "\"\"\"\n",
    "key: biopsy_id\n",
    "value: stage_number 0,1,2,3,4 (exclude NaN)\n",
    "\"\"\"\n",
    "for idx, row in train_df.iterrows():\n",
    "    train_outcome_map[row['biopsy_id']] = row['label']\n",
    "\n",
    "train_slide_map = {}\n",
    "\"\"\"\n",
    "key: slide_id\n",
    "value: Tuple(biopsy_id, slide_path)\n",
    "\"\"\"\n",
    "for idx, row in train_mapping.iterrows():\n",
    "    train_slide_map[row['slide_id']] = (row['biopsy_id'], row['downsampled_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c3bdd-20d6-407a-b778-0b22f8af962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outcome_map = {}\n",
    "\"\"\"\n",
    "key: biopsy_id\n",
    "value: stage_number 0,1,2,3,4 (exclude NaN)\n",
    "\"\"\"\n",
    "for idx, row in test_df.iterrows():\n",
    "    test_outcome_map[row['biopsy_id']] = row['label']\n",
    "\n",
    "test_slide_map = {}\n",
    "\"\"\"\n",
    "key: slide_id\n",
    "value: Tuple(biopsy_id, slide_path)\n",
    "\"\"\"\n",
    "for idx, row in test_mapping.iterrows():\n",
    "    test_slide_map[row['slide_id']] = (row['biopsy_id'], row['downsampled_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71cd1-5d16-472f-80be-28d5fba31e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [] # img_path\n",
    "train_y = [] # stage label\n",
    "for slide_id in train_slide_map:\n",
    "    # print(slide_id)\n",
    "    biopsy_id, img_path = train_slide_map[slide_id]\n",
    "    label = train_outcome_map[biopsy_id]\n",
    "    train_x.append(img_path)\n",
    "    train_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8305f3-74f6-4309-9487-132dcb2b429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [] # img_path\n",
    "test_y = [] # stage label\n",
    "for slide_id in test_slide_map:\n",
    "    # print(slide_id)\n",
    "    biopsy_id, img_path = test_slide_map[slide_id]\n",
    "    label = test_outcome_map[biopsy_id]\n",
    "    test_x.append(img_path)\n",
    "    test_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c3427-30e6-4d2e-a3b0-93beda382eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_x), len(train_y), len(test_x), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598811d5-516f-4165-ad77-5774415ce2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug_train = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomResizedCrop(size=224,scale=(0.8,1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transform_aug_test = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.RandomResizedCrop(size=224,scale=(0.8,1.0)),\n",
    "        # transforms.RandomRotation(degrees=15),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8426b-56f3-4413-91ff-632597396188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, x, y, mode='train'): \n",
    "        self.x = x # img_path\n",
    "        self.y = y # label\n",
    "        self.mode = mode # train/test\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.x[index]\n",
    "        x_pil = Image.open(path)\n",
    "        if self.mode=='train': x_tensor = transform_aug_train(x_pil)\n",
    "        elif self.mode == 'test': x_tensor = transform_aug_test(x_pil)\n",
    "        return x_tensor, self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aec716-267c-45e4-a93d-ec074edd8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay=0 # 1e-8\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a4783-0f99-4928-a666-f5a723c37bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_x, train_y, mode='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataset = ImageDataset(test_x, test_y, mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ec54a-957e-424d-9ca7-1e601afa333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in test_dataset:\n",
    "#     x, y = data\n",
    "#     print(x.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38402106-b269-4379-89a0-70dce3757a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_list = []\n",
    "# train_y_list = train_y\n",
    "# for i in tqdm(range(len(train_x))):\n",
    "#     path = train_x[i]\n",
    "#     x_pil = Image.open(path)\n",
    "#     x_tensor = transform_aug_train(x_pil)\n",
    "#     train_x_list.append(x_tensor)\n",
    "\n",
    "# test_x_list = []\n",
    "# test_y_list = test_y\n",
    "# for i in tqdm(range(len(test_x))):\n",
    "#     path = test_x[i]\n",
    "#     x_pil = Image.open(path)\n",
    "#     x_tensor = transform_aug_test(x_pil)\n",
    "#     test_x_list.append(x_tensor)\n",
    "\n",
    "# pd.to_pickle({'x': train_x_list, 'y': train_y_list}, f'./train.pkl')\n",
    "# pd.to_pickle({'x': test_x_list, 'y': test_y_list}, f'./test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051102c-ceb1-4271-8444-7eaeba3bdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_pred, y_true):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    return loss_fn(y_pred, y_true)\n",
    "\n",
    "def focal_mse_loss(inputs, targets, activate='sigmoid', beta=.2, gamma=1):\n",
    "    loss = (inputs - targets) ** 2\n",
    "    loss *= (torch.tanh(beta * torch.abs(inputs - targets))) ** gamma if activate == 'tanh' else \\\n",
    "        (2 * torch.sigmoid(beta * torch.abs(inputs - targets)) - 1) ** gamma\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def huber_loss(inputs, targets, beta=1.):\n",
    "    l1_loss = torch.abs(inputs - targets)\n",
    "    cond = l1_loss < beta\n",
    "    loss = torch.where(cond, 0.5 * l1_loss ** 2 / beta, l1_loss - 0.5 * beta)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "criterion = mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91861924-ce40-4632-9740-54ce96cb5d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b0f76-e41e-440b-93e8-9a605e5799b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, scheduler):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    for step, data in enumerate(dataloader):\n",
    "        batch_x, batch_y = data\n",
    "        batch_x, batch_y = (\n",
    "            batch_x.float().to(device),\n",
    "            batch_y.float().to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        output = torch.squeeze(output, dim=0)\n",
    "        # print(output.shape, batch_y.shape)\n",
    "        loss = loss_fn(output, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    metric_train_loss = np.array(train_loss).mean()\n",
    "    scheduler.step(metric_train_loss)\n",
    "    return metric_train_loss\n",
    "\n",
    "def val_epoch(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_pred_y = model(valid_x.to(device))\n",
    "        metric_valid = mse_loss(valid_pred_y, valid_y.to(device)).item()\n",
    "    return metric_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5842d16-104b-4420-9b8b-2ba22a4772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(num_classes=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "hidden_dim = model.fc.in_features\n",
    "out_dim = 1\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(hidden_dim, hidden_dim//4),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(hidden_dim//4, out_dim),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('./checkpoints/resnet18-f37072fd.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda0015-3854-45a3-bdeb-46ccc2a963ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 1e8\n",
    "for epoch in range(epochs):\n",
    "    # print(f'Running epoch {epoch} ...')\n",
    "    train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler\n",
    "    )\n",
    "    metric_valid = val_epoch(model, test_loader)\n",
    "    if metric_valid < best_score:\n",
    "        best_score = metric_valid\n",
    "        print(\"Saving best model ...\")\n",
    "        print(\"Val Score:\", metric_valid)\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            f\"./checkpoints/model.ckpt\",\n",
    "        )\n",
    "    print(f\"Epoch {epoch}: Loss = {train_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
